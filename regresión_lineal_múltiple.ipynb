{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionLinealMultiple:  \n",
    "    import statsmodels.formula.api as smf\n",
    "    \n",
    "    def __init__(self, url=None, y=None, **kwargs):\n",
    "        self.url = url\n",
    "        self.y = y\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def variables_x(self):\n",
    "        l = []\n",
    "        for i in self.kwargs:\n",
    "            l.append(i)\n",
    "        return l\n",
    "        \n",
    "    def join_variables_x(self):\n",
    "        var_x = self.variables_x()\n",
    "        modelo_variables = '+'.join(var_x)\n",
    "        return modelo_variables\n",
    "    \n",
    "    def modelo_multiple(self):\n",
    "        \n",
    "        import pandas as pd\n",
    "        import statsmodels.formula.api as smf\n",
    "        \n",
    "        data = pd.read_csv(self.url)     \n",
    "        variables_x = self.y + '~' + self.join_variables_x()\n",
    "        lm = smf.ols(formula = variables_x, data = data).fit()\n",
    "        return lm\n",
    "    \n",
    "    def view_model(self):\n",
    "        #import statsmodels.formula.api as smf\n",
    "        view = self.modelo_multiple()\n",
    "        return view.summary()              \n",
    "        \n",
    "    def parameters_pvalues_rsquared(self):\n",
    "        model = self.modelo_multiple()\n",
    "        print('Parametros del modelo:\\n{}\\n-----------'.format(model.params))\n",
    "        print('P_valores del modelo:\\n{}\\n-----------'.format(model.pvalues))\n",
    "        print('R_cuadrada del modelo:\\n{}\\n-----------'.format(model.rsquared))\n",
    "        print('R_cuadrada ajustada del modelo:\\n{}\\n-----------'.format(model.rsquared_adj))\n",
    "        #print('Según el modelo: Sales = {} + {}*\"TV\" + {}*\"Newspaper\" '.format(model.params[0], model.params[1], model.params[2]))\n",
    "       \n",
    "    def prediccion_y(self):\n",
    "        \n",
    "        import pandas as pd\n",
    "        \n",
    "        \"\"\"\n",
    "         Llamamos a la función 'variables_x()' para obtener los nombre de\n",
    "         las variables x y pasarlas por la función 'predict'.         \n",
    "        \"\"\"\n",
    "         \n",
    "        model = self.modelo_multiple()\n",
    "        data = pd.read_csv(self.url)\n",
    "        y_pred = model.predict(data[self.variables_x()])\n",
    "        return y_pred\n",
    "    \n",
    "    def error(self):\n",
    "        \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        count_var = len(self.variables_x())\n",
    "        data = pd.read_csv(self.url) \n",
    "        SSD = sum((data[self.y]-self.prediccion_y())**2)\n",
    "        RSE = np.sqrt(SSD/(len(data)-count_var-1))\n",
    "        e = RSE / np.mean(data[self.y])\n",
    "        # La salida de esta función, detalla el porcentaje de error que no puede explicar el modelo, entre menor sea es mejor para el modelo.\n",
    "        return e\n",
    "    \n",
    "    # Multicolinealidad\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/joanby/python-ml-course/master/datasets/ads/Advertising.csv'\n",
    "regre_mult = RegresionLinealMultiple(url = path, y = 'Sales', TV = 'TV', Radio='Radio', Newspaper='Newspaper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TV+Radio+Newspaper'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regre_mult.join_variables_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multicolinealidad:\n",
    "    \n",
    "    def __init__(self, url=None, var_1=None, **kwargs):\n",
    "        self.url = url\n",
    "        self.kwargs = kwargs\n",
    "        self.var_1 = var_1\n",
    "               \n",
    "    def variables(self):\n",
    "        return self.var_1\n",
    "    \n",
    "    def variables_y(self):\n",
    "        l = []\n",
    "        for i in self.kwargs:\n",
    "            l.append(i)\n",
    "            \n",
    "        var = '+'.join(l)\n",
    "        \n",
    "        m = self.var_1 + '~' + var\n",
    "        return m\n",
    "    \n",
    "    def funcion_multi(self):\n",
    "        \n",
    "        import statsmodels.formula.api as smf\n",
    "        import pandas as pd\n",
    "        \n",
    "        l = []\n",
    "        for i in self.kwargs:\n",
    "            l.append(i)\n",
    "            \n",
    "        var = '+'.join(l)\n",
    "        \n",
    "        m = self.var_1 + '~' + var\n",
    "\n",
    "        data = pd.read_csv(self.url)\n",
    "        lm = smf.ols(formula = m, data = data).fit()\n",
    "        rsquare = lm.rsquared\n",
    "        VIF = 1/(1-rsquare)\n",
    "        # El VIF es el factor de inflación de la varianza, y se usa cuando se \n",
    "        # tienen problemas de multicolinealidad, esto se da cuando existe coorrelación entre\n",
    "        # variables predictoras\n",
    "        return VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/joanby/python-ml-course/master/datasets/ads/Advertising.csv'\n",
    "m = Multicolinealidad(url = url , var_1 = 'Newspaper', TV='TV', Radio='Radio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Newspaper'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Newspaper~TV+Radio'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1451873787239286"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.funcion_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validacion:\n",
    "    \n",
    "    def __init__(self, url=None, var_1=None, **kwargs):\n",
    "        self.url = 'https://raw.githubusercontent.com/joanby/python-ml-course/master/datasets/ads/Advertising.csv'\n",
    "        self.var_1 = var_1\n",
    "        self.kwargs = kwargs  \n",
    "        \n",
    "    def variables_y(self):\n",
    "        l = []\n",
    "        for i in self.kwargs:\n",
    "            l.append(i)\n",
    "        var = '+'.join(l)\n",
    "        m = self.var_1 + '~' + var\n",
    "        return m\n",
    "    \n",
    "    def datos(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import statsmodels.formula.api as smf\n",
    "        data = pd.read_csv(self.url)\n",
    "        a = np.random.randn(len(data))\n",
    "        check = (a<0.8)\n",
    "        # Nos indica que el 80% de los datos se usaran para entrenar al modelo\n",
    "        training = data[check]\n",
    "        # Lo contrario de check, el 20% se usara para testing\n",
    "        testing = data[~check]\n",
    "        # Esta función compara los datos training vs testing\n",
    "        lm = smf.ols(formula = self.variables_y(), data = training).fit()\n",
    "        return lm\n",
    "    \n",
    "    def detalle(self):\n",
    "        return self.datos().summary()\n",
    "    \n",
    "    \n",
    "    def histograma(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.hist(self.datos())\n",
    "        # Dividir el dataset en conjunto de entrenamiento y de testing\n",
    "        \n",
    "    def predict_testing(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        data = pd.read_csv(self.url)\n",
    "        a = np.random.randn(len(data))\n",
    "        check = (a<0.8)\n",
    "        # Nos indica que el 80% de los datos se usaran para entrenar al modelo\n",
    "        training = data[check]\n",
    "        # Lo contrario de check, el 20% se usara para testing\n",
    "        testing = data[~check]\n",
    "        predict = self.datos().predict(testing)\n",
    "        return predict\n",
    "    \n",
    "    def error(self):\n",
    "        \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        data = pd.read_csv(self.url)\n",
    "        a = np.random.randn(len(data))\n",
    "        check = (a<0.8)\n",
    "        # Nos indica que el 80% de los datos se usaran para entrenar al modelo\n",
    "        training = data[check]\n",
    "        # Lo contrario de check, el 20% se usara para testing\n",
    "        testing = data[~check]\n",
    "        predict = self.datos().predict(testing)\n",
    "        SSD = sum((testing['Sales'] - predict)**2)\n",
    "        \n",
    "        l = []\n",
    "        for i in self.kwargs:\n",
    "            l.append(i)\n",
    "        \n",
    "        RSE = np.sqrt(SSD/(len(testing)-len(l)-1))\n",
    "        \n",
    "        var_y_mean = np.mean(testing[self.var_1])\n",
    "        \n",
    "        err = RSE/var_y_mean\n",
    "        \n",
    "        return err\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1b72af217b8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = Validacion(var_1 = 'Sales', TV='TV', Radio='Radio')\n",
    "v.datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1304402126052511"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   639.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Dec 2018</td> <th>  Prob (F-statistic):</th> <td>4.60e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:20:17</td>     <th>  Log-Likelihood:    </th> <td> -315.43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   163</td>      <th>  AIC:               </th> <td>   636.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   160</td>      <th>  BIC:               </th> <td>   646.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.9817</td> <td>    0.331</td> <td>    9.009</td> <td> 0.000</td> <td>    2.328</td> <td>    3.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0457</td> <td>    0.002</td> <td>   29.053</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.1844</td> <td>    0.009</td> <td>   20.308</td> <td> 0.000</td> <td>    0.166</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>57.277</td> <th>  Durbin-Watson:     </th> <td>   1.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 154.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.449</td> <th>  Prob(JB):          </th> <td>3.04e-34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.785</td> <th>  Cond. No.          </th> <td>    421.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.889\n",
       "Model:                            OLS   Adj. R-squared:                  0.887\n",
       "Method:                 Least Squares   F-statistic:                     639.9\n",
       "Date:                Tue, 11 Dec 2018   Prob (F-statistic):           4.60e-77\n",
       "Time:                        20:20:17   Log-Likelihood:                -315.43\n",
       "No. Observations:                 163   AIC:                             636.9\n",
       "Df Residuals:                     160   BIC:                             646.1\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.9817      0.331      9.009      0.000       2.328       3.635\n",
       "TV             0.0457      0.002     29.053      0.000       0.043       0.049\n",
       "Radio          0.1844      0.009     20.308      0.000       0.166       0.202\n",
       "==============================================================================\n",
       "Omnibus:                       57.277   Durbin-Watson:                   1.871\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              154.354\n",
       "Skew:                          -1.449   Prob(JB):                     3.04e-34\n",
       "Kurtosis:                       6.785   Cond. No.                         421.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.detalle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas Importantes\n",
    "\n",
    "* Un incremento en el estadistico F, es sinonimo de que las variables que se agregaron son mejor que las anteriores. Es sinonimo de una mejora en el modelo y quiere decir que esa nueva variable, predice mejor en conjunto que el modelo tal cual estaba sin ella.\n",
    "* Cuanto menor sea el pvalor para estimar de las variables predictoras mejor es añadir esa variable predictora al modelo \n",
    "* El RSE es el valor estandar de los residuos, cada que se añade una variable nueva, este indicador decrece, lo que indica una m\n",
    "* El error es lo que el modelo no puede explicar y se representa en porcentaje, este nos indica que existe x% de datos que no pueden ser explicados, entre menor sea es mejor para el modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
